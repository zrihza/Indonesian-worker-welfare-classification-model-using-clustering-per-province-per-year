{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1dygqHl-RYE0PmGXP74G__HNnnpjzoOT4","timestamp":1744884398978},{"file_id":"1d7-aiqmhHzOhHJtdj5TaBJnyf1pIN-rs","timestamp":1729232680021}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **1. Import Library**"],"metadata":{"id":"fKADPWcFKlj3"}},{"cell_type":"code","source":["# === Import all required libraries ===\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import randint\n","from sklearn.metrics import classification_report"],"metadata":{"id":"BlmvjLY9M4Yj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2. Memuat Dataset dari Hasil Clustering**"],"metadata":{"id":"f3YIEnAFKrKL"}},{"cell_type":"code","source":["# Load the dataset\n","df = pd.read_csv('Dataset_inisiasi.csv')\n","\n","# Display the first few rows\n","print(\"Preview of the dataset:\")\n","print(df.head())"],"metadata":{"id":"GHCGNTyrM5fS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744963154894,"user_tz":-420,"elapsed":15,"user":{"displayName":"Ihza Zhafran","userId":"04580463849486476391"}},"outputId":"be41a649-8cb4-419d-fb0b-696d87bcaf99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Preview of the dataset:\n","  provinsi    jenis     daerah   tahun    periode        gk        ump  \\\n","0     ACEH  MAKANAN  PERKOTAAN  2015.0      MARET  293697.0  1900000.0   \n","1     ACEH  MAKANAN  PERKOTAAN  2015.0  SEPTEMBER  302128.0  1900000.0   \n","2     ACEH  MAKANAN  PERKOTAAN  2016.0      MARET  306243.0  2118500.0   \n","3     ACEH  MAKANAN  PERKOTAAN  2016.0  SEPTEMBER  319768.0  2118500.0   \n","4     ACEH  MAKANAN  PERDESAAN  2015.0      MARET  297479.0  1900000.0   \n","\n","       peng     upah  Cluster  \n","0  466355.0  11226.0        0  \n","1  466355.0  11226.0        0  \n","2  548853.0  13627.0        0  \n","3  548853.0  13627.0        0  \n","4  395136.0  11226.0        0  \n"]}]},{"cell_type":"markdown","source":["# **3. Data Splitting**"],"metadata":{"id":"KkPem5eWL2UP"}},{"cell_type":"markdown","source":["The Data Splitting stage aims to separate the dataset into two parts: training set and test set."],"metadata":{"id":"YYj1rl_JNI9Y"}},{"cell_type":"markdown","source":["Before we do splitting, let's scale the data first because we will try KNN algorithm which need to be scaled first."],"metadata":{"id":"o1uHqKToDqId"}},{"cell_type":"code","source":["df_processed = df.copy()\n","\n","numeric_cols = df_processed.select_dtypes(include=['int64', 'float64']).columns.drop('Cluster')\n","categorical_cols = df_processed.select_dtypes(include='object').columns\n","\n","scaler_std = StandardScaler()\n","\n","# Apply both scalings\n","df_processed[numeric_cols] = scaler_std.fit_transform(df_processed[numeric_cols])"],"metadata":{"id":"iExkHTEw33gv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next we encode the categorical columns so that the Machine can process the data."],"metadata":{"id":"0K0wchj-D1v0"}},{"cell_type":"code","source":["# Identify categorical columns\n","categorical_cols = df_processed.select_dtypes(include='object').columns\n","\n","# Apply Label Encoding to each categorical column\n","label_encoders = {}\n","le = LabelEncoder()\n","for col in categorical_cols:\n","    df_processed[col] = le.fit_transform(df_processed[col])\n","    label_encoders[col] = le  # store encoder if needed for inverse_transform"],"metadata":{"id":"p9AnDWpxOGrI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Since the provinsi is highly correlated to the cluster feature, we should drop it."],"metadata":{"id":"ub7TafGWD_1V"}},{"cell_type":"code","source":["# Drop the 'provinsi' column BEFORE splitting\n","df_processed = df_processed.drop(columns='provinsi')"],"metadata":{"id":"hJYsdxb60mPZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Setting the target."],"metadata":{"id":"EbObVvAzEHbu"}},{"cell_type":"code","source":["# Set target column\n","target_column = 'Cluster'\n","\n","# Split the dataset into features and target\n","X = df_processed.drop(columns=target_column)\n","y = df_processed[target_column]\n","\n","# Split into training and testing sets (80% train, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.3, random_state=42, stratify=y\n",")\n","\n","# Display the shape of the resulting datasets\n","print(f\"Training set shape: {X_train.shape}\")\n","print(f\"Test set shape: {X_test.shape}\")"],"metadata":{"id":"OubAW-7ONKVj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744963154996,"user_tz":-420,"elapsed":28,"user":{"displayName":"Ihza Zhafran","userId":"04580463849486476391"}},"outputId":"d661695e-9d7c-4750-92c0-1b54d1627bc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set shape: (1430, 8)\n","Test set shape: (614, 8)\n"]}]},{"cell_type":"markdown","source":["# **4. Membangun Model Klasifikasi**\n"],"metadata":{"id":"IVPbB03CMhTT"}},{"cell_type":"markdown","source":["## **a. Membangun Model Klasifikasi**"],"metadata":{"id":"Ned1pL9zMmBK"}},{"cell_type":"markdown","source":["After the data ready to be processed, let's build the models, here i use several model at once so we can pick the best model."],"metadata":{"id":"WAWzPOE4Nkti"}},{"cell_type":"code","source":["# Initialize all models\n","models = {\n","    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n","    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n","    \"Random Forest\": RandomForestClassifier(random_state=42),\n","    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n","    \"Naive Bayes\": GaussianNB()\n","}\n","\n","# Train the models\n","for name, model in models.items():\n","    model.fit(X_train, y_train)\n","    print(f\"{name} model trained ‚úÖ\")"],"metadata":{"id":"4JYxBe87NLDk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744963155817,"user_tz":-420,"elapsed":820,"user":{"displayName":"Ihza Zhafran","userId":"04580463849486476391"}},"outputId":"f7c35442-7103-41f9-b1ad-ab216e291893"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Logistic Regression model trained ‚úÖ\n","Decision Tree model trained ‚úÖ\n","Random Forest model trained ‚úÖ\n","K-Nearest Neighbors model trained ‚úÖ\n","Naive Bayes model trained ‚úÖ\n"]}]},{"cell_type":"markdown","source":["## **b. Evaluasi Model Klasifikasi**"],"metadata":{"id":"ergzChZFEL-O"}},{"cell_type":"markdown","source":["Next let's evaluate the model."],"metadata":{"id":"zOm68u-7NpLT"}},{"cell_type":"code","source":["# Evaluate the models\n","for name, model in models.items():\n","    y_pred = model.predict(X_test)\n","\n","    print(f\"=== {name} ===\")\n","    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","    print(\"Precision:\", precision_score(y_test, y_pred, average='weighted', zero_division=0))\n","    print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n","    print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n","    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n","    print(\"-\" * 40)"],"metadata":{"id":"tMq4QAssNLip","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744963156332,"user_tz":-420,"elapsed":513,"user":{"displayName":"Ihza Zhafran","userId":"04580463849486476391"}},"outputId":"30c0ef4f-4a5e-4446-9e75-95b95d8e8f63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Logistic Regression ===\n","Accuracy: 0.6514657980456026\n","Precision: 0.6536025696183717\n","Recall: 0.6514657980456026\n","F1 Score: 0.6507546927188375\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.63      0.70      0.66       303\n","           1       0.67      0.60      0.64       311\n","\n","    accuracy                           0.65       614\n","   macro avg       0.65      0.65      0.65       614\n","weighted avg       0.65      0.65      0.65       614\n","\n","----------------------------------------\n","=== Decision Tree ===\n","Accuracy: 0.8990228013029316\n","Precision: 0.8990228013029316\n","Recall: 0.8990228013029316\n","F1 Score: 0.8990228013029316\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.90      0.90      0.90       303\n","           1       0.90      0.90      0.90       311\n","\n","    accuracy                           0.90       614\n","   macro avg       0.90      0.90      0.90       614\n","weighted avg       0.90      0.90      0.90       614\n","\n","----------------------------------------\n","=== Random Forest ===\n","Accuracy: 0.8403908794788274\n","Precision: 0.8405615483796046\n","Recall: 0.8403908794788274\n","F1 Score: 0.8403959599830456\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.83      0.85      0.84       303\n","           1       0.85      0.83      0.84       311\n","\n","    accuracy                           0.84       614\n","   macro avg       0.84      0.84      0.84       614\n","weighted avg       0.84      0.84      0.84       614\n","\n","----------------------------------------\n","=== K-Nearest Neighbors ===\n","Accuracy: 0.6237785016286646\n","Precision: 0.6238347055414559\n","Recall: 0.6237785016286646\n","F1 Score: 0.6234337266100357\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.62      0.59      0.61       303\n","           1       0.62      0.65      0.64       311\n","\n","    accuracy                           0.62       614\n","   macro avg       0.62      0.62      0.62       614\n","weighted avg       0.62      0.62      0.62       614\n","\n","----------------------------------------\n","=== Naive Bayes ===\n","Accuracy: 0.5944625407166124\n","Precision: 0.5961369224769092\n","Recall: 0.5944625407166124\n","F1 Score: 0.5935736082433114\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.58      0.64      0.61       303\n","           1       0.61      0.55      0.58       311\n","\n","    accuracy                           0.59       614\n","   macro avg       0.60      0.60      0.59       614\n","weighted avg       0.60      0.59      0.59       614\n","\n","----------------------------------------\n"]}]},{"cell_type":"markdown","source":["‚úÖ Top Performer: Decision Tree\n","Accuracy: 89.9% - wow, almost 90%!\n","\n","All metrics are balanced, meaning the model understands your data well. But be careful: Decision Tree is prone to overfitting, especially if the depth is not limited.\n","\n","ü•à Runner-Up: Random Forest\n","Accuracy: 84.0%\n","\n","Random Forest generalizes more than Decision Tree, so it's usually more reliable on real-world data.\n","\n","Precision and Recall are balanced - a very good sign!\n","\n","üòê Mid-tier: Logistic Regression & KNN\n","LogReg: 65% accuracy - still usable for baseline.\n","\n","KNN: 62% accuracy - a bit low, might be improved by tuning n_neighbors.\n","\n","üö´ Naive Bayes\n","Accuracy: 59.4% - probably not suitable for your data.\n","It could be because your data doesn't meet the independence assumption between features favored by Naive Bayes."],"metadata":{"id":"H4_9OwrsXZlz"}},{"cell_type":"markdown","source":["Since the accuracy of the decision tree is very high, which risks overfit, I will choose random forest.\n","\n","But i think we can improve the accuracy using model tuning, so let's do hyperparammeter tuning."],"metadata":{"id":"P_8_XYE7E1LO"}},{"cell_type":"markdown","source":["## **c. Tuning Model Klasifikasi (Optional)**"],"metadata":{"id":"ph9yIYDXEPuB"}},{"cell_type":"markdown","source":["Here i use randomized search for the tuning."],"metadata":{"id":"-Bikx3LINv5e"}},{"cell_type":"code","source":["# Inisialisasi model dasar\n","rf = RandomForestClassifier(random_state=42)\n","\n","# Definisikan ruang hyperparameter\n","param_dist = {\n","    'n_estimators': [100, 200, 300, 400, 500],\n","    'max_depth': [5, 10, 20, None],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'max_features': ['sqrt', 'log2'],\n","    'bootstrap': [True, False]\n","}"],"metadata":{"id":"winbFzb8NL95"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"],"metadata":{"id":"hE7pqlEPEYzI"}},{"cell_type":"markdown","source":["Next let's evaluate the result after tuning.\n","\n","But this process may take a while."],"metadata":{"id":"feaPESoeN0zz"}},{"cell_type":"code","source":["# Randomized Search CV\n","rf_random = RandomizedSearchCV(\n","    estimator=rf,\n","    param_distributions=param_dist,\n","    n_iter=50,\n","    cv=5,\n","    verbose=2,\n","    n_jobs=-1,\n","    scoring='accuracy',\n","    random_state=42\n",")\n","\n","# Fit ke data kamu\n","rf_random.fit(X_train, y_train)\n","\n","# Cek hasil terbaik\n","print(\"Best parameters:\", rf_random.best_params_)\n","print(\"Best accuracy:\", rf_random.best_score_)"],"metadata":{"id":"HTXZRvEeNMb1","executionInfo":{"status":"ok","timestamp":1744965605615,"user_tz":-420,"elapsed":182210,"user":{"displayName":"Ihza Zhafran","userId":"04580463849486476391"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1213004a-62cd-435e-bc58-e96456cb5add"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 50 candidates, totalling 250 fits\n","Best parameters: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': None, 'bootstrap': False}\n","Best accuracy: 0.8664335664335665\n"]}]},{"cell_type":"code","source":["best_rf = rf_random.best_estimator_\n","y_pred = best_rf.predict(X_test)\n","\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HCQW288bGWUq","executionInfo":{"status":"ok","timestamp":1744966348511,"user_tz":-420,"elapsed":73,"user":{"displayName":"Ihza Zhafran","userId":"04580463849486476391"}},"outputId":"18eadde6-b9a1-479c-b8d7-9b0601a3b270"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.89      0.92      0.90       303\n","           1       0.92      0.88      0.90       311\n","\n","    accuracy                           0.90       614\n","   macro avg       0.90      0.90      0.90       614\n","weighted avg       0.90      0.90      0.90       614\n","\n"]}]},{"cell_type":"markdown","source":["## **e. Analisis Hasil Evaluasi Model Klasifikasi**"],"metadata":{"id":"ZRsOdm4uEgAW"}},{"cell_type":"markdown","source":["Comparison of Evaluation Results (Before & After Tuning)\n","\n","Model | Accuracy | Precision | Recall | F1 Score\n","\n","Random Forest (Before tuning) | 84.0% | 0.84 | 0.84 | 0.84\n","\n","Random Forest (After tuning) | 90.0% | 0.89‚Äì0.92 | 0.88‚Äì0.92 | 0.90\n","\n","---\n","\n","After tuning, the model experienced significant improvements in all metrics.\n","\n","Not only is it more accurate, but it is also more balanced in handling both classes (class 0 and 1).\n","\n","---"],"metadata":{"id":"hZdGIwC_Gzni"}},{"cell_type":"markdown","source":["Model Weakness Identification\n","üìä Classification Result Report:\n","\n","Cluster 0:\n","\n","Precision: 0.89\n","\n","Recall: 0.92\n","\n","Cluster 1:\n","\n","Precision: 0.92\n","\n","Recall: 0.88\n","\n","---\n","üß† Interpretation:\n","\n","The model is slightly better at recognizing class 0 than class 1, judging from the slightly lower recall of class 1 (0.88).\n","\n","However, this is still within a very good range and does not show extreme discrepancies.\n","\n","üéØ Overfitting / Underfitting?\n","Accuracy on cross-validation (best score): 86.6%\n","\n","Accuracy on test set: 90%\n","\n","---\n","**Conclusion**: The model is not overfitting. Instead, it is quite stable and likely to generalize well.\n","\n","---"],"metadata":{"id":"V87Jxu7wHJiC"}},{"cell_type":"markdown","source":["Recommended Further Actions\n","\n","\n","If want to go deeper:\n","\n","üîç Try ensemble voting or stacking classifier techniques.\n","\n","üîç Try SMOTE or class weighting approaches in case the data becomes imbalanced.\n","\n","üß™ Experiment with XGBoost or LightGBM - often outperform Random Forest in the case of structured data.\n","\n","Preventive measures:\n","\n","Make sure the data cleaning pipeline is solid.\n","\n","Keep adding data where possible (the more data, the more stable the model)."],"metadata":{"id":"SNNvcA7hHgYR"}}]}